# Manuscript Integration Hooks

This note captures the locations of quantitative results and figures generated by the CAMI benchmark (`bench/`) and the case-study + ablation tooling (`case/`). Populate the manuscript and supplement by pointing to the artefacts listed below.

## Results Section

- **Multi-dataset CAMI outcomes** – `bench/out/summary_per_tool_per_sample.tsv` (profile metrics per rank) and `bench/out/leaderboard_by_rank.tsv` (mean L1/Bray–Curtis, Precision/Recall/F1).
- **Real-world case study** – `case/out/<sample>/top_taxa.tsv`, `case/out/<sample>/hymet/profile.cami.tsv`, optional `case/out/<sample>/metaphlan/*.tsv`. Runtime/memory: `case/out/runtime_memory.tsv` (stage = `run`).
- **Database ablation behaviour** – `case/ablation_summary.tsv` (fallback percentages), ablated profiles under `case/ablation/<sample>/level_*/hymet/`. Runtime deltas recorded in `case/out/runtime_memory.tsv` (stage = `ablation_<level>`).

## Methods Section

- **Shared-DB policy** – Database builders and reference provenance documented in `bench/README.md` (§5). Note MetaPhlAn4 retains its official marker database (`bench/run_metaphlan4.sh`).
- **Command reproducibility** – Environment specification (`bench/environment.yml`), runtime tracking (`bench/out/runtime_memory.tsv`, `case/out/runtime_memory.tsv`), and runner scripts (`bench/run_all_cami.sh`, `case/run_case.sh`, `case/run_ablation.sh`).
- **Seeds** – `case/ablate_db.py` uses a deterministic seed (`--seed`, default 1337) when sampling sequences to drop.

## Tables

- **Database composition** – Summaries from `bench/db/*/.build.stamp` plus ablation logs (`case/ablation/refsets/ablation_summary.tsv`).
- **Per-dataset metrics** – CAMI: `bench/out/summary_per_tool_per_sample.tsv`; Case study: `case/out/<sample>/top_taxa.tsv`; Ablation: `case/ablation_summary.tsv`.
- **Absolute time/memory** – `bench/out/runtime_memory.tsv` and `case/out/runtime_memory.tsv` (columns: wall, user, sys, max_rss_gb, I/O MB).

## Figures

- **CAMI performance plots** – `bench/plot/make_figures.py` generates `fig_accuracy_by_rank.png`, `fig_f1_by_rank.png`, `fig_l1_braycurtis.png`, `fig_per_sample_f1_stack.png`. Update colour palette before manuscript submission if needed.
- **Case-study visuals** – Use `case/out/<sample>/top_taxa.tsv` (bar chart) and `case/out/<sample>/metaphlan/comparison.tsv` for cross-tool comparisons.
- **Ablation curves** – Build from `case/ablation_summary.tsv` (rank fallback) and the corresponding runtime entries (stage-prefixed rows in `case/out/runtime_memory.tsv`).

## Citations & Clarifications

- Ensure manuscript text explicitly states “contigs-only” evaluation.
- Reference competing tools (Metalign, KrakenUniq, ganon2, Centrifuger, Taxor, sourmash gather) when discussing baselines.
- Document seeds and deterministic sampling choices (e.g., `case/ablate_db.py --seed`).

Keep this file synchronized with repository outputs whenever benchmarks or case-study runs are updated.
